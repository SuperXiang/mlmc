{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiYOdkfjUxM0",
        "colab_type": "code",
        "outputId": "2ee33ca9-08fb-4dc6-943a-904591d0738b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install emoji\n",
        "!pip install pyenchant\n",
        "!pip install nltk\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from pytorch_transformers import AdamW\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from torch import Tensor\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, multilabel_confusion_matrix\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.3.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.10.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.19)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.85)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.35)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.13.36)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->pytorch-transformers) (2.6.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n",
            "Collecting pyenchant\n",
            "  Using cached https://files.pythonhosted.org/packages/9e/54/04d88a59efa33fefb88133ceb638cdf754319030c28aadc5a379d82140ed/pyenchant-2.0.0.tar.gz\n",
            "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WferBeSfVxA",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TERgHUWTepkR",
        "colab_type": "code",
        "outputId": "b13c0743-f884-4907-8531-b369281b8ba3",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Upload train.tsv and validation.tsv\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3332705b-c3d4-4675-8805-5277664cb268\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3332705b-c3d4-4675-8805-5277664cb268\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving validation.tsv to validation.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whdx5ATGFQ5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Represent labels as one-hot encoded vectors\n",
        "train_df = pd.read_csv(\"train.tsv\", delimiter='\\t')\n",
        "test_df = pd.read_csv(\"validation.tsv\", delimiter='\\t')\n",
        "train_tweets = train_df.tweet.values\n",
        "test_tweets = test_df.tweet.values\n",
        "label_names=[\"anger\",\"disgust\",\"fear\",\"joy\",\"sadness\",\"surprise\"]\n",
        "label_ids=[1,2,3,4,5,6]\n",
        "train_labels=[]\n",
        "for i in range(len(train_df)):\n",
        "    train_label=[]\n",
        "    for key in label_names:\n",
        "        train_label.append(int(train_df.iloc[i][key]))\n",
        "    train_labels.append(train_label)\n",
        "test_labels=[]\n",
        "for i in range(len(test_df)):\n",
        "    test_label=[]\n",
        "    for key in label_names:\n",
        "        test_label.append(int(test_df.iloc[i][key]))\n",
        "    test_labels.append(test_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuFHE_7PGIJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d5abec99-a676-491d-c2ba-b489e7ad4202"
      },
      "source": [
        "# Pre-processing\n",
        "import regex as re\n",
        "import emoji\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "ps = PorterStemmer()\n",
        "def preprocess(tweets, negation_handling = True, links_handling = True, stopword=True):\n",
        "  max = 0\n",
        "  clean_tweets = []\n",
        "  # NLTK stop words\n",
        "  stop_words = set(stopwords.words('english')) \n",
        "  for tweet in tweets:\n",
        "    if links_handling:\n",
        "      # Delete links and mentions\n",
        "      tweet = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", tweet)\n",
        "    neg_feature = re.compile(r\"^not$|never|[a-z]n't$\")   # regular expression for not, n't and never\n",
        "    negation = False\n",
        "    # Tweet to list of words\n",
        "    words=word_tokenize(tweet)\n",
        "    if stopword:\n",
        "    # Delete the stopwords\n",
        "      words = [w for w in words if not w in stop_words]\n",
        "    for i in range(len(words)): \n",
        "      if negation_handling:\n",
        "        #Add NOT_ to every word after not, n't and never until punctuation\n",
        "        if (words[i] not in (',', '.', '?', '!', ';')) & negation:\n",
        "            words[i] = \"NOT_\" + words[i]\n",
        "        if neg_feature.search(words[i]):\n",
        "            negation = True\n",
        "        if words[i] in (',', '.', '?', '!', ';'):\n",
        "            negation = False\n",
        "    tweet = ' '.join(word for word in words)\n",
        "    clean_tweets.append(tweet)\n",
        "  #Add begining and end of sentence tokens\n",
        "  clean_tweets = [tweet + \" [SEP] [CLS]\" for tweet in clean_tweets]\n",
        "  return clean_tweets"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVvhZ_x36cZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XLNetForMultiLabelSequenceClassification(XLNetForSequenceClassification):\n",
        "    r\"\"\"\n",
        "        Method overriding of XLNetForSequenceClassification to adapt it to multi-label classification \n",
        "        Changes: labels vector is extended to the number labels instead of 1\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, input_mask=None, attention_mask=None,\n",
        "                mems=None, perm_mask=None, target_mapping=None,\n",
        "                labels=None, head_mask=None):\n",
        "        transformer_outputs = self.transformer(input_ids, token_type_ids=token_type_ids,\n",
        "                                               input_mask=input_mask, attention_mask=attention_mask,\n",
        "                                               mems=mems, perm_mask=perm_mask, target_mapping=target_mapping,\n",
        "                                               head_mask=head_mask)\n",
        "        output = transformer_outputs[0]\n",
        "\n",
        "        output = self.sequence_summary(output)\n",
        "        logits = self.logits_proj(output)\n",
        "\n",
        "        # Keep mems, hidden states, attentions if there are in it\n",
        "        outputs = (logits,) + transformer_outputs[1:]\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "        #Changes: labels vector is extended to the number labels instead of 1\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels),\n",
        "                            labels.view(-1, self.num_labels).type_as(logits.view(-1, self.num_labels)))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCqAz5Va-SXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xlnet_model(train_tweets, test_tweets, train_labels, test_labels, epochs = 4, batch_size = 32, lr = 3e-5, T=0.5):\n",
        "    \"\"\"\n",
        "    lr = learning rate\n",
        "    T = probabilistic threshold\n",
        "    \"\"\"\n",
        "    tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    tokenized_train = [tokenizer.tokenize(sent) for sent in train_tweets]\n",
        "    train_inputs = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_train]\n",
        "    train_inputs = pad_sequences(train_inputs, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    # Create attention masks\n",
        "    train_masks = []\n",
        "    # Create a mask of 1s for each token followed by 0s for padding\n",
        "    for seq in train_inputs:\n",
        "      seq_mask = [float(i>0) for i in seq]\n",
        "      train_masks.append(seq_mask)\n",
        "\n",
        "    tokenized_test = [tokenizer.tokenize(sent) for sent in test_tweets]\n",
        "    test_inputs = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_test]\n",
        "    test_inputs = pad_sequences(test_inputs, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    # Create attention masks\n",
        "    test_masks = []\n",
        "    # Create a mask of 1s for each token followed by 0s for padding\n",
        "    for seq in test_inputs:\n",
        "      seq_mask = [float(i>0) for i in seq]\n",
        "      test_masks.append(seq_mask)\n",
        "\n",
        "    train_inputs = torch.tensor(train_inputs)\n",
        "    test_inputs = torch.tensor(test_inputs)\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    test_labels = torch.tensor(test_labels)\n",
        "    train_masks = torch.tensor(train_masks)\n",
        "    test_masks = torch.tensor(test_masks)\n",
        "\n",
        "    # Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "    # with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "    # Load XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top. \n",
        "\n",
        "    model = XLNetForMultiLabelSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=6)\n",
        "    model.cuda()\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "    # This variable contains all of the hyperparemeter information that the training loop needs\n",
        "    optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                        lr=lr)\n",
        "    # Store the loss\n",
        "    train_loss_set = []\n",
        "\n",
        "\n",
        "    # trange is a tqdm wrapper around the normal python range\n",
        "    for _ in trange(epochs, desc=\"Epoch\"):\n",
        "      \n",
        "      \n",
        "      # Training\n",
        "      \n",
        "      # Set our model to training mode (as opposed to evaluation mode)\n",
        "      model.train()\n",
        "      \n",
        "      # Tracking variables\n",
        "      tr_loss = 0\n",
        "      nb_tr_examples, nb_tr_steps = 0, 0\n",
        "      \n",
        "      # Train the data for one epoch\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Clear out the gradients (by default they accumulate)\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        train_loss_set.append(loss.item())    \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        # Update tracking variables\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "      print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    # test\n",
        "    # Put model in evaluation mode to evaluate loss on the test set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss=0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    labels,predictions=[],[]\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in test_dataloader:\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and speeding up test\n",
        "      with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        logits = output[0]\n",
        "      \n",
        "      # Move logits and labels to CPU\n",
        "\n",
        "      prob=torch.sigmoid(logits)\n",
        "      # If probability greater than or equal to threshold T the tweet contains that emotion\n",
        "      pred = (prob >= T).type(torch.FloatTensor)\n",
        "      pred = pred.detach().cpu().numpy().astype(int).tolist()\n",
        "      label_ids = b_labels.to('cpu').numpy().tolist()\n",
        "      labels+=label_ids\n",
        "      predictions+=pred\n",
        "    labels=np.array(labels)\n",
        "    predictions=np.array(predictions)\n",
        "    recall_micro=recall_score(labels, predictions, average = \"micro\")\n",
        "    recall_macro=recall_score(labels, predictions, average = \"macro\")\n",
        "    precision_micro=precision_score(labels, predictions, average = \"micro\")\n",
        "    precision_macro=precision_score(labels, predictions, average = \"macro\")\n",
        "    f1_micro=f1_score(labels, predictions, average = \"micro\")\n",
        "    f1_macro=f1_score(labels, predictions, average = \"macro\")\n",
        "    model_metrics={(\"Precision\",\"Micro\"):precision_micro,(\"Precision\",\"Macro\"):precision_macro,\n",
        "                  (\"Recall\",\"Micro\"):recall_micro,(\"Recall\",\"Macro\"):recall_macro,\n",
        "                  (\"F1 score\",\"Micro\"):f1_micro,(\"F1 score\",\"Macro\"):f1_macro}\n",
        "    confusion_matrix_ = multilabel_confusion_matrix(labels, predictions)\n",
        "    print(model_metrics)\n",
        "    return model_metrics, confusion_matrix_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql4MohtF6wdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grid Search for hyper-parameter tuning\n",
        "from sklearn.model_selection import KFold\n",
        "hps = [\n",
        "(4, 32, 2e-5,0.5),\n",
        "(2, 32, 2e-5,0.5),\n",
        "(3, 32, 2e-5,0.5),\n",
        "(3, 48, 2e-5,0.5),\n",
        "(4, 32, 3e-5,0.3),\n",
        "(4, 32, 3e-5,0.5),\n",
        "(4, 32, 3e-5,0.8),\n",
        "]\n",
        "kfold_tweets = preprocess(train_tweets)\n",
        "# 10-fold cross validation\n",
        "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
        "val_scores = []\n",
        "for epochs, batch_size, lr, T in hps:\n",
        "  hp_scores = []\n",
        "  for train_index, test_index in cv.split(kfold_tweets):\n",
        "    tr_tweets = preprocess(train_tweets[train_index])\n",
        "    va_tweets = preprocess(train_tweets[test_index])\n",
        "    tr_labels = [train_labels[i] for i in train_index]\n",
        "    va_labels = [train_labels[i] for i in test_index]\n",
        "    hp_scores.append(xlnet_model(tr_tweets, va_tweets, tr_labels, va_labels, epochs, batch_size, lr, T)[0])\n",
        "  hp_score_df = pd.DataFrame(hp_scores)\n",
        "  hp_score = dict(hp_score_df.mean())\n",
        "  val_scores.append((str(epochs)+\", \"+str(batch_size)+\", \"+str(lr)+\", \"+str(T), hp_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn10nsU6c1Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(val_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC7C7ecDYOEV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9EuVs2yQjCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 4\n",
        "lr = 3e-5\n",
        "T = 0.5\n",
        "# testing\n",
        "clean_train_tweets, clean_test_tweets = (preprocess(train_tweets), preprocess(test_tweets))\n",
        "test_scores = xlnet_model(clean_train_tweets, clean_test_tweets, train_labels, test_labels, epochs, batch_size, lr, T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4d4LnUgwk0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}